@article{Zeger2020,
abstract = {The PCORI mission is to address questions about health care from the patients' perspective, such as "What is my health status and its trajectory?" and "What are my treatment options and the expected benefits and harms of each?" The purpose of this PCORI-funded project is to make it easier for clinicians and patients to find valid answers to these and other clinical questions by using modern digital tools that support (1) learning from the experience of prior patients, and (2) translating what is learned to inform the decision at hand, taking into account each patient's unique circumstances. For this project, we developed and implemented statistical methods called bayesian hierarchical models that combine existing data on past clinical experience from a reference population with new measurements for the individual. Clinicians currently use such methods when screening patients for disease. Modern technologies make it possible for this proven approach to extend far beyond its current use. The recent revolution in information technology has unleashed new types of health data, from DNA sequences to functional images of the brain to patient-reported outcomes. Furthermore, the electronic health record captures every patient's sequence of health measurements, diagnoses, and treatments. The bayesian methods developed and reported on here combine even complex data to produce predictions about an individual patient's health status, trajectory, and likely benefits and harms of interventions. In addition to developing novel methods, we facilitated their use by creating and locally disseminating a software package, OSLER inHealth, that will allow other researchers to apply this methodology. The software repository is open-source and includes the methodology developed as part of this research as well as other existing methods that facilitate individualized health prediction. We have tested the proposed methods and software on 3 case studies to (1) estimate the frequency with which various pathogens cause children's pneumonia and predict which pathogen is likely to be causing a particular child's pneumonia given her or his clinical data, potentially reducing unnecessary use of antibiotics; (2) infer whether a prostate cancer is indolent or aggressive for a patient under active surveillance; and (3) characterize the variation in multiple, time-varying symptoms of major mental disorders, including schizophrenia and depression, and then use this knowledge to provide patient-specific estimates of past and, likely, future trajectories. With this project, we have developed and demonstrated the value of combining even complex measurements on a population of patients, then translating this experience into more valid assessments of a new patient's health status and trajectory. The model also supports inferences about the likely benefits and harms associated with available interventions. Copyright {\textcopyright} 2020. Johns Hopkins Bloomberg School of Public Health. All Rights Reserved.},
author = {Zeger, Scott L and Wu, Zhenke and Coley, Yates and Fojo, Anthony Todd and Carter, Bal and O'Brien, Katherine and Zandi, Peter and Cooke, Mary and Carey, Vince and Crainiceanu, Ciprian and Muscelli, John and Gherman, Adrian and Mekosh, Jason},
mendeley-groups = {CapStone_2025/CapStone_DS_2025},
number = {2020},
title = {{Using a Bayesian Approach to Predict Patients' Health and Response to Treatment}},
url = {http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=medp&NEWS=N&AN=37708307},
year = {2020}
}

@article{Chatzimichail2023,
abstract = {Medical diagnosis is the basis for treatment and management decisions in healthcare. Conventional methods for medical diagnosis commonly use established clinical criteria and fixed numerical thresholds. The limitations of such an approach may result in a failure to capture the intricate relations between diagnostic tests and the varying prevalence of diseases. To explore this further, we have developed a freely available specialized computational tool that employs Bayesian inference to calculate the posterior probability of disease diagnosis. This novel software comprises of three distinct modules, each designed to allow users to define and compare parametric and nonparametric distributions effectively. The tool is equipped to analyze datasets generated from two separate diagnostic tests, each performed on both diseased and nondiseased populations. We demonstrate the utility of this software by analyzing fasting plasma glucose, and glycated hemoglobin A1c data from the National Health and Nutrition Examination Survey. Our results are validated using the oral glucose tolerance test as a reference standard, and we explore both parametric and nonparametric distribution models for the Bayesian diagnosis of diabetes mellitus.},
author = {Chatzimichail, Theodora and Hatjimihail, Aristides T.},
doi = {10.3390/DIAGNOSTICS13193135,},
file = {:C\:/Users/Namita/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chatzimichail, Hatjimihail - 2023 - A Bayesian Inference Based Computational Tool for Parametric and Nonparametric Medical Diagnosis.pdf:pdf},
issn = {20754418},
journal = {Diagnostics},
keywords = {Bayesian diagnosis,Bayesian inference,copula distribution,diabetes mellitus,kernel density estimator,likelihood,nonparametric distribution,parametric distribution,posterior probability,prior probability,probability density function},
mendeley-groups = {CapStone_2025},
month = {oct},
number = {19},
publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
title = {{A Bayesian Inference Based Computational Tool for Parametric and Nonparametric Medical Diagnosis}},
url = {https://pubmed.ncbi.nlm.nih.gov/37835877/},
volume = {13},
year = {2023}
}


@article{VandeSchoot2021,
abstract = {Bayesian statistics is an approach to data analysis based on Bayes' theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events. This Primer describes the stages involved in Bayesian analysis, from specifying the prior and data models to deriving inference, model checking and refinement. We discuss the importance of prior and posterior predictive checking, selecting a proper technique for sampling from a posterior distribution, variational inference and variable selection. Examples of successful applications of Bayesian analysis across various research fields are provided, including in social sciences, ecology, genetics, medicine and more. We propose strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist. Finally, we outline the impact of Bayesian analysis on artificial intelligence, a major goal in the next decade.},
author = {van de Schoot, Rens and Depaoli, Sarah and King, Ruth and Kramer, Bianca and M{\"{a}}rtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
doi = {10.1038/s43586-020-00001-2},
file = {:C\:/Users/Namita/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van de Schoot et al. - 2021 - Bayesian statistics and modelling.pdf:pdf},
issn = {2662-8449},
journal = {Nature Reviews Methods Primers},
keywords = {Scientific community,Statistics},
mendeley-groups = {CapStone_2025},
month = {jan},
number = {1},
pages = {1},
publisher = {Springer Nature},
title = {{Bayesian statistics and modelling}},
url = {https://www.nature.com/articles/s43586-020-00001-2},
volume = {1},
year = {2021}
}


@article{Klauenberg2015,
abstract = {Regression is a common task in metrology and often applied to calibrate instruments, evaluate inter-laboratory comparisons or determine fundamental constants, for example. Yet, a regression model cannot be uniquely formulated as a measurement function, and consequently the Guide to the Expression of Uncertainty in Measurement (GUM) and its supplements are not applicable directly. Bayesian inference, however, is well suited to regression tasks, and has the advantage of accounting for additional a priori information, which typically robustifies analyses. Furthermore, it is anticipated that future revisions of the GUM shall also embrace the Bayesian view. Guidance on Bayesian inference for regression tasks is largely lacking in metrology. For linear regression models with Gaussian measurement errors this tutorial gives explicit guidance. Divided into three steps, the tutorial first illustrates how a priori knowledge, which is available from previous experiments, can be translated into prior distributions from a specific class. These prior distributions have the advantage of yielding analytical, closed form results, thus avoiding the need to apply numerical methods such as Markov Chain Monte Carlo. Secondly, formulas for the posterior results are given, explained and illustrated, and software implementations are provided. In the third step, Bayesian tools are used to assess the assumptions behind the suggested approach. These three steps (prior elicitation, posterior calculation, and robustness to prior uncertainty and model adequacy) are critical to Bayesian inference. The general guidance given here for Normal linear regression tasks is accompanied by a simple, but real-world, metrological example. The calibration of a flow device serves as a running example and illustrates the three steps. It is shown that prior knowledge from previous calibrations of the same sonic nozzle enables robust predictions even for extrapolations.},
author = {Klauenberg, Katy and W{\"{u}}bbeler, Gerd and Mickan, Bodo and Harris, Peter and Elster, Clemens},
doi = {10.1088/0026-1394/52/6/878},
file = {:C\:/Users/Namita/Downloads/Klauenberg_2015_Metrologia_52_878.pdf:pdf;:C\:/Users/Namita/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Klauenberg et al. - 2015 - A tutorial on Bayesian Normal linear regression.pdf:pdf},
issn = {16817575},
journal = {Metrologia},
keywords = {Bayesian inference,Gaussian measurement error,Normal inverse Gamma distribution,conjugate prior distribution,linear regression,prior knowledge,sonic nozzle calibration},
mendeley-groups = {CapStone_2025},
number = {6},
pages = {878--892},
publisher = {IOP Publishing},
title = {{A tutorial on Bayesian Normal linear regression}},
volume = {52},
year = {2015}
}


@article{DeLeeuw2012a,
abstract = {In most research, linear regression analyses are performed without taking into account published results (i.e., reported summary statistics) of similar previous studies. Although the prior density in Bayesian linear regression could accommodate such prior knowledge, formal models for doing so are absent from the literature. The goal of this article is therefore to develop a Bayesian model in which a linear regression analysis on current data is augmented with the reported regression coefficients (and standard errors) of previous studies. Two versions of this model are presented. The first version incorporates previous studies through the prior density and is applicable when the current and all previous studies are exchangeable. The second version models all studies in a hierarchical structure and is applicable when studies are not exchangeable. Both versions of the model are assessed using simulation studies. Performance for each in estimating the regression coefficients is consistently superior to using current data alone and is close to that of an equivalent model that uses the data from previous studies rather than reported regression coefficients. Overall the results show that augmenting data with results from previous studies is viable and yields significant improvements in the parameter estimation. {\textcopyright} 2012 Copyright Taylor and Francis Group, LLC.},
author = {de Leeuw, Christiaan and Klugkist, Irene},
doi = {10.1080/00273171.2012.673957},
file = {:C\:/Users/Namita/Downloads/Augmenting Data With Published Results in Bayesian Linear Regression.pdf:pdf},
issn = {00273171},
journal = {Multivariate Behavioral Research},
mendeley-groups = {CapStone_2025},
number = {3},
pages = {369--391},
title = {{Augmenting Data With Published Results in Bayesian Linear Regression}},
volume = {47},
year = {2012}
}


@article{Liu2013,
abstract = {Background: A Bayesian clinical reasoning model was developed to predict an individual risk for cardiovascular disease (CVD) for desk-top reference. Methods: Three Bayesian models were constructed to estimate the CVD risk by sequentially incorporating demographic features (basic), six metabolic syndrome components (metabolic score) and conventional risk factors (enhanced model). By considering clinical weights (regression coefficients) of each model as normal distribution, individual risk can be predicted making allowance for uncertainty of clinical weights. A community-based cohort that enrolled 64,489 participants free of CVD at baseline and followed up over five years to ascertain newly diagnosed CVD cases during the period through 2000 to 2004 was used for the illustration of the three proposed models (full empirical data are available from website http://homepage.ntu.edu.tw/$\sim$chenlin/CVD-prediction-data.rar). Results: The proposed models can be applied to predicting the CVD risk with any combination of risk factors. For a 47-year-old man, the five-year risk for CVD with the basic model was 11.2% (95% CI: 7.8%-15.6%). His metabolic syndrome score, leading to 1.488 of likelihood ratio, enhanced the risk for CVD up to 15.8% (95% CI: 11.0%-21.5%) and put him in highest deciles. As with the habit of smoking over 2 packs per-day and family history of CVD, yielding the likelihood ratios of 1.62 and 1.47, respectively, the risk was further raised to 30.9% (95% CI: 20.7%-39.8%). Conclusions: We demonstrate how to make individual risk prediction for CVD by incorporating routine information with a sequential Bayesian clinical reasoning approach. {\textcopyright} 2012 Elsevier Ireland Ltd.},
author = {Liu, Yi Ming and Chen, Sam Li Sheng and Yen, Amy Ming Fang and Chen, Hsiu Hsi},
doi = {10.1016/J.IJCARD.2012.05.016},
file = {:C\:/Users/Namita/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2013 - Individual risk prediction model for incident cardiovascular disease A Bayesian clinical reasoning approach(9).pdf:pdf},
issn = {0167-5273},
journal = {International Journal of Cardiology},
keywords = {Bayes' theorem,Bayesian,Cardiovascular disease,Likelihood ratio,Metabolic syndrome,Prediction model},
mendeley-groups = {CapStone_2025},
month = {sep},
number = {5},
pages = {2008--2012},
pmid = {22658349},
publisher = {Elsevier},
title = {{Individual risk prediction model for incident cardiovascular disease: A Bayesian clinical reasoning approach}},
url = {https://www.sciencedirect.com/science/article/pii/S0167527312006274},
volume = {167},
year = {2013}
}

@article{Haselimashhadi2018,
abstract = {Discrete data are collected in many application areas and are often characterised by highly-skewed distributions. An example of this, which is considered in this paper, is the number of visits to a specialist, often taken as a measure of demand in healthcare. A discrete Weibull regression model was recently proposed for regression problems with a discrete response and it was shown to possess desirable properties. In this paper, we propose the first Bayesian implementation of this model. We consider a general parametrization, where both parameters of the discrete Weibull distribution can be conditioned on the predictors, and show theoretically how, under a uniform non-informative prior, the posterior distribution is proper with finite moments. In addition, we consider closely the case of Laplace priors for parameter shrinkage and variable selection. Parameter estimates and their credible intervals can be readily calculated from their full posterior distribution. A simulation study and the analysis of four real datasets of medical records show promises for the wide applicability of this approach to the analysis of count data. The method is implemented in the R package BDWreg.},
author = {Haselimashhadi, H. and Vinciotti, V. and Yu, K.},
doi = {10.1080/02664763.2017.1342782},
file = {:C\:/Users/Namita/Downloads/EBSCO-FullText-09_09_2025.pdf:pdf},
issn = {13600532},
journal = {Journal of Applied Statistics},
keywords = {Bayesian inference,Discrete Weibull,discrete response},
mendeley-groups = {CapStone_2025},
number = {6},
pages = {1085--1105},
title = {{A novel Bayesian regression model for counts with an application to health data}},
volume = {45},
year = {2018}
}


@article{Dillon2011,
abstract = {Currently available U.S. population-based data for ankylosing spondylitis (AS), spondyloarthritis and inflammatory back pain (IBP) from the nationally representative U.S. National Health and Nutrition Examination Survey (NHANES) include both NHANES I (1971-1975) and NHANES II (1976-1980) surveys. The pelvic radiographs obtained in NHANES I provided U.S. prevalence estimates for radiographic sacroiliitis, an important component of the AS case definition. AS and spondyloarthritis prevalences cannot readily be calculated from NHANES I survey data; however, IBP prevalence (Rudwaleit et al Criteria 7b) can be estimated from NHANES II. The NHANES II estimate for IBP is 0.8% of the adult population ages 25 to 49 years. The prevalence of IBP in the subset of persons with a history of a back pain episode lasting 2 or more weeks was 6.7%. The 2009-2010 NHANES U.S. Inflammatory Back Pain/Spondyloarthritis survey is currently fielded. {\textcopyright} Copyright 2011 Southern Society for Clinical Investigation.},
author = {Dillon, Charles F. and Hirsch, Rosemarie},
doi = {10.1097/MAJ.0b013e31820f8c83},
file = {:C\:/Users/Namita/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dillon, Hirsch - 2011 - The United States National Health and Nutrition Examination Survey and the epidemiology of ankylosing spondyliti.pdf:pdf},
issn = {00029629},
journal = {American Journal of the Medical Sciences},
keywords = {Inflammatory back pain,NHANES,Prevalence,Spondyloarthritis,Survey,United States},
mendeley-groups = {CapStone_2025/CapStone_DS_2025},
number = {4},
pages = {281--283},
pmid = {21358307},
publisher = {Lippincott Williams and Wilkins},
title = {{The United States National Health and Nutrition Examination Survey and the epidemiology of ankylosing spondylitis}},
volume = {341},
year = {2011}
}


@article{Hutchon2005,
author = {Hutchon, David J.R. and Chitty, Roger N. and McCrossin, Robert and Gill, Christopher J. and Sabin, Lora and Schmid, Christopher H.},
doi = {10.1136/bmj.330.7504.1369-d},
file = {:C\:/Users/Namita/Downloads/bmj33001080.pdf:pdf;:C\:/Users/Namita/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutchon et al. - 2005 - Why clinicians are natural bayesians 4.pdf:pdf},
issn = {09598146},
journal = {British Medical Journal},
mendeley-groups = {CapStone_2025,CapStone_2025/CapStone_DS_2025},
number = {7504},
pages = {1390--1391},
title = {{Why clinicians are natural bayesians [4]}},
volume = {330},
year = {2005}
}


@article{M.L.2014,
abstract = {Objectives. Obesity is a known risk factor for type 2 diabetes (T2D). We conducted a case-control study to assess the association between body mass index (BMI) and the risk of being diagnosed with T2D in the United States. Methods. We selected adults (≥ 18 years old) who were diagnosed with T2D (defined by ICD-9-CM diagnosis codes or use of anti-diabetic medications) between January 2004 and October 2011 ("cases") from an electronic health records database provided by an integrated health system in the Middle Atlantic region. Twice as many individuals enrolled in the health system without a T2D diagnosis during the study period ("controls") were selected based on age, sex, history of cardiac comorbidities or hyperinflammatory state (defined by C-reactive protein and erythrocyte sedimentation rate), and use of psychiatric or beta blocker medications. BMI was measured during one year prior to the first observed T2D diagnosis (for cases) or a randomly assigned date (for controls); individuals with no BMI measure or BMI < 18.5 kg/m2 were excluded. We assessed the impact of increased BMI (overweight: 25-29.9 kg/m2; Obesity Class I: 30-34.9 kg/m2; Obesity Class II: 35-39.9 kg/m 2; Obesity Class III: ≥40 kg/m2), relative to normal BMI (18.5-24.9 kg/m2), on a T2D diagnosis using odds ratios (OR) and relative risks (RR) estimated from multiple logistic regression results. Results: We included 12,179 cases (mean age: 55, 43{%} male) and 25,177 controls (mean age: 56, 45{%} male). We found a positive association between BMI and the risk of a T2D diagnosis. The strength of this association increased with BMI category (RR [95{%} confidence interval]: overweight, 1.5 [1.4-1.6]; Obesity Class I, 2.5 [2.3-2.6]; Obesity Class II, 3.6 [3.4-3.8]; Obesity Class III, 5.1 [4.7-5.5]). Conclusions: BMI is strongly and independently associated with the risk of being diagnosed with T2D. The incremental association of BMI category on the risk of T2D is stronger for people with a higher BMI relative to people with a lower BMI. {\textcopyright} 2014 Ganz et al.; licensee BioMed Central Ltd.},
author = {M.L., Ganz and N., Wintfeld and Q., Li and V., Alas and J., Langer and M., Hammer},
file = {:C\:/Users/Namita/Downloads/1758-5996-6-50.pdf:pdf},
issn = {1758-5996},
journal = {Diabetology and Metabolic Syndrome},
keywords = {C reactive protein,ICD-9-CM,United States,acute heart infarction,adult,angina pectoris,anticonvulsive agent,antidiabetic agent,antihypertensive agent,antilipemic agent,antiobesity agent,anxiety disorder,anxiolytic agent,article,beta adrenergic receptor blocking agent,body mass,body weight,case control study,clinical assessment,comorbidity,controlled study,depression,diabetic patient,disease association,electronic medical record,erythrocyte sedimentation rate,female,health care system,heart disease,human,hyperlipidemia,hypertension,inflammation,ischemic heart disease,laboratory test,major clinical study,male,middle aged,neuroleptic agent,non insulin dependent diabetes mellitus,obesity,patient selection,priority journal,risk factor},
mendeley-groups = {CapStone_2025},
number = {1},
pages = {1--8},
title = {{The association of body mass index with the risk of type 2 diabetes: A case-control study nested in an electronic health records system in the United States}},
url = {http://www.embase.com/search/results?subaction=viewrecord%7B&%7Dfrom=export%7B&%7Did=L372827357%5Cnhttp://dx.doi.org/10.1186/1758-5996-6-50%5Cnhttp://zp9vv3zm2k.search.serialssolutions.com/?sid=EMBASE%7B&%7Dissn=17585996%7B&%7Did=doi:10.1186%7B%25%7D2F175},
volume = {6},
year = {2014}
}

@article{Austin2021,
abstract = {Missing data is a common occurrence in clinical research. Missing data occurs when the value of the variables of interest are not measured or recorded for all subjects in the sample. Common approaches to addressing the presence of missing data include complete-case analyses, where subjects with missing data are excluded, and mean-value imputation, where missing values are replaced with the mean value of that variable in those subjects for whom it is not missing. However, in many settings, these approaches can lead to biased estimates of statistics (eg, of regression coefficients) and/or confidence intervals that are artificially narrow. Multiple imputation (MI) is a popular approach for addressing the presence of missing data. With MI, multiple plausible values of a given variable are imputed or filled in for each subject who has missing data for that variable. This results in the creation of multiple completed data sets. Identical statistical analyses are conducted in each of these complete data sets and the results are pooled across complete data sets. We provide an introduction to MI and discuss issues in its implementation, including developing the imputation model, how many imputed data sets to create, and addressing derived variables. We illustrate the application of MI through an analysis of data on patients hospitalised with heart failure. We focus on developing a model to estimate the probability of 1-year mortality in the presence of missing data. Statistical software code for conducting MI in R, SAS, and Stata are provided.},
author = {Austin, Peter C. and White, Ian R. and Lee, Douglas S. and van Buuren, Stef},
doi = {10.1016/j.cjca.2020.11.010},
file = {:C\:/Users/Namita/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Austin et al. - 2021 - Missing Data in Clinical Research A Tutorial on Multiple Imputation.pdf:pdf},
issn = {0828282X},
journal = {Canadian Journal of Cardiology},
mendeley-groups = {CapStone_2025/CapStone_DS_2025},
month = {sep},
number = {9},
pages = {1322--1331},
pmid = {33276049},
publisher = {Elsevier Inc.},
title = {{Missing Data in Clinical Research: A Tutorial on Multiple Imputation}},
url = {https://onlinecjc.ca/action/showFullText?pii=S0828282X20311119 https://onlinecjc.ca/action/showAbstract?pii=S0828282X20311119 https://onlinecjc.ca/article/S0828-282X(20)31111-9/abstract},
volume = {37},
year = {2021}
}




