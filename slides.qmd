---
title: "Bayesian Logistic Regression Application in Diabetes Probability Prediction"
subtitle: "CapStone project Presentation"
author: "Namita Mishra (Advisor: Dr. Ashraf Cohen)"
date: '`r Sys.Date()`'
format:
  revealjs
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!

More information about `revealjs`:
<https://quarto.org/docs/reference/formats/presentations/revealjs.html>
:::

## Introduction

-   Type 2 Diabetes (T2D), a public health concern worldwide - body
    doesn’t make enough insulin or can’t use the insulin it makes
    causing increase in blood sugar level posing risks of heart disease
    and other organ damage

-   Understanding factors contributing to Diabetes age, body mass index
    (BMI): early intervention at population level.

-   Problem: Traditional statistical approaches fail to analyze complex
    relationships or uncertainty present in healthcare data.

## Goal: Address challenges in healthcare data analysis where traditional statistical approaches fail

-   To analyze complex relationships or uncertainty in predictions, we
    compare both Frequentist and Bayesian methods on the NHANES dataset.

-   Identify the association of risk factors for diabetes prediction and
    measure the predictive performance of the model, demonstrating
    methodological perspectives to enhance actionable insights in
    healthcare.

## Methods

-   A study conducted on NHANES dataset aims to determine how healthcare
    data with missing values can be analyzed using Bayesian regression
    Model.
-   Bayesian Regression Model was found appropriate for the given data,
    based on the data characteristics and the model characteristics

Bayesian Regression Model - - could incorporation of prior knowledge
could stabilize the estimates - could account for uncertainty and
provide full posterior distributions, offering robust inference than
traditional frequentist methods, where estimates are unstable - can
handle imputation to handle missing data toperform Bayesian regression
@Austin2021

Data Source
-([NHANES](https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?BeginYear=2013))
from NHANES (CDC) .xpt files imported using r from three datasets
(demographics, exam, questionnaire). Selected variables were merged into
a dataframe, cleaned, and explored for analysis to predict the
probability of diabetes (Response variable) based on BMI, age, and race
(Predictors).

| Dataset | Key variables     | Dimensions |
|---------|-------------------|------------|
| demo1   | age, race, gender | 10175 × 47 |
| exam1   | BMI               | 9813 × 224 |
| quest1  | Diabetes          | 9813 × 953 |

## Data Exploration and Visualization

-   Data has a small sample for certain subgroups in the BMI category
    (pre-diabetic category is underrepresented, n=132/9813)
-   Missing values return only (14) complete cases - imbalance in
    observed diabetes outcomes (Yes \> No), with age range of (0 - 80
    years) where very young participants (0–10 years) in the study are
    unusual for diabetes, considering the prior knowledge that diabetes
    is rare in children
-   Survey-weighted proportions reflect population estimates of Male:
    female :: 48.9%: 51%, majority participants fall into Non-Hispanic
    White category and under normal weight category
-   Predictor interactions and correlations are complex or hierarchical
    in structure
-   The weighted proportions are suitable for running Bayesian
    regression that represents the US population

## Data Exploration and Visualization {.smaller}

```{r, warning=FALSE, echo=F, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r warning=FALSE}
#| eval: false
#| include: false
# Load Data
#kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

## Modeling and Results

Data preprocessing:

-   Raw data analysis: finds quasi-separation due to listwise deletion
    of missing values with a resulting small sample size, revealing
    missingness due to MAR or MNAR

-   Multiple Imputation, data analytics, and visuals

    -   Missingness - No NA's and the sample size was retained

    -   Trace plots and density plots - compare distributions of imputed
        vs observed values

    -   Quality check on imputation - Number of imputations, means,
        variances, and proportions for consistency of all datasets
        generated, VIFs or correlations, and structural violations for
        categorical variables

    -   Standardization of continuous predictors and ensuring outcome
        variability is maintained

    Bayesian Logistic Regression analytics and findings from posteriors

    -   

-   **Tell a story about what the data reveals**

```{r}


```

## Bayesian probability equation

P(β,Ymis​∣Yobs​,X)∝P(Yobs​,Ymis​∣X,β)⋅P(β)

## Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
